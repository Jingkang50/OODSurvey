# 5. OOD Detection

## 5.1 Classfication-based Method
### 5.1.0 Baseline
**[ICLR-2017]**
[A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/abs/1610.02136).
Hendrycks, Dan and Gimpel, Kevin
> <details>
> <summary> The starting point of OOD detection. It uses softmax probabilities.</summary>
> <p class="small" style="text-align:left">
> Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection.
> </p>
> </details>
---


### 5.1.1 Confidence Calibration

#### Post-hoc Calibration
**[ICLR-2017]**
[A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/abs/1610.02136).
Hendrycks, Dan and Gimpel, Kevin
> <details>
> <summary> The starting point of OOD detection. It uses softmax probabilities.</summary>
> <p class="small" style="text-align:left">
> Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection.
> </p>
> </details>

#### Bayesian Methods
**[ODIN-2017]**
[A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/abs/1610.02136).
Hendrycks, Dan and Gimpel, Kevin
> <details>
> <summary> The starting point of OOD detection. It uses softmax probabilities.</summary>
> <p class="small" style="text-align:left">
> Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection.
> </p>
> </details>

**[ODIN-2017]**
[A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/abs/1610.02136).
Hendrycks, Dan and Gimpel, Kevin
> <details>
> <summary> The starting point of OOD detection. It uses softmax probabilities.</summary>
> <p class="small" style="text-align:left">
> Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection.
> </p>
> </details>

#### Other Confidence Enhancement Methods
**[ODIN-2017]**
[A baseline for detecting misclassified and out-of-distribution examples in neural networks](https://arxiv.org/abs/1610.02136).
Hendrycks, Dan and Gimpel, Kevin
> <details>
> <summary> The starting point of OOD detection. It uses softmax probabilities.</summary>
> <p class="small" style="text-align:left">
> Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection.
> </p>
> </details>

---




### 5.1.2 Outlier Exposure






---

## Label Space Redesign

**[arXiv-2021]** 
[Exploring the Limits of Out-of-Distribution Detection](https://arxiv.org/abs/2106.03004).
Fort, Stanislav and Ren, Jie and Lakshminarayanan, Balaji.
<details>
  <summary>  </summary>
  
</details>

**[CVPR-2021]**
[MOS: Towards Scaling Out-of-distribution Detection for Large Semantic Space](https://arxiv.org/abs/2105.01879).
Huang, Rui and Li, Yixuan.
<details>
  <summary>  </summary>
  
</details>

**[NeurIPS-2018]**
[Out-of-Distribution Detection using Multiple Semantic Label Representations](https://arxiv.org/abs/1808.06664). 
Shalev, Gabi and Adi, Yossi and Keshet, Joseph.
<details>
  <summary>  </summary>
  
</details>

**[CVPR-2018]**
[Hierarchical Novelty Detection for Visual Object Recognition](https://arxiv.org/abs/1804.00722). 
Lee, Kibok and Lee, Kimin and Min, Kyle and Zhang, Yuting and Shin, Jinwoo and Lee, Honglak.
<details>
  <summary>  </summary>
  
</details>
---


## Big Pretrained Model


---



